# recsys/data.py
from __future__ import annotations
import os
from typing import Optional, Tuple, List
import pandas as pd


CANDIDATE_FILENAMES: List[str] = ["merged_data.txt", "merged_data.csv"]


def _resolve_path(data_dir_or_file: str) -> str:
    """Tráº£ vá» Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i tá»›i file merged (txt/csv)."""
    p = os.path.abspath(data_dir_or_file)

    # Truyá»n trá»±c tiáº¿p file
    if os.path.isfile(p):
        return p

    # Truyá»n thÆ° má»¥c: thá»­ ngay trong thÆ° má»¥c
    for name in CANDIDATE_FILENAMES:
        cand = os.path.join(p, name)
        if os.path.exists(cand):
            return os.path.abspath(cand)

    # DÃ² trong thÆ° má»¥c con
    for root, _, files in os.walk(p):
        for name in CANDIDATE_FILENAMES:
            if name in files:
                return os.path.abspath(os.path.join(root, name))

    raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y merged_data (.txt/.csv) bÃªn dÆ°á»›i: {p}")


def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    rename_map = {
        "UserID": "userId", "userID": "userId", "USERID": "userId",
        "MovieID": "movieId", "movieID": "movieId", "MOVIEID": "movieId",
        "Rating": "rating", "RATING": "rating",
        "Date": "date", "DATE": "date", "Timestamp": "date", "timestamp": "date",
    }
    for src, dst in rename_map.items():
        if src in df.columns and dst not in df.columns:
            df.rename(columns={src: dst}, inplace=True)
    return df


def load_netflix_prize(data_dir: str, nrows: Optional[int] = None) -> Tuple[pd.DataFrame, pd.DataFrame, None]:
    """
    Äá»c dá»¯ liá»‡u Netflix Prize (file merged lá»›n) theo CHUNKS Ä‘á»ƒ trÃ¡nh trÃ n RAM.
    - data_dir: thÆ° má»¥c chá»©a file hoáº·c Ä‘Æ°á»ng dáº«n file trá»±c tiáº¿p.
    - nrows: náº¿u Ä‘áº·t, chá»‰ Ä‘á»c tá»‘i Ä‘a nrows dÃ²ng (há»¯u Ã­ch Ä‘á»ƒ test nhanh).
    Tráº£ vá»: ratings, movies, None
    """
    file_path = _resolve_path(data_dir)
    print(f"ğŸ“‚ Äang Ä‘á»c file: {file_path}")

    # Äá»‹nh nghÄ©a dtype nháº¹ Ä‘á»ƒ giáº£m RAM ngay tá»« lÃºc parse
    # (náº¿u file cÃ³ header khÃ¡c sáº½ Ä‘Æ°á»£c chuáº©n hoÃ¡ sau)
    dtype_hint = {
        "userId": "int32",
        "movieId": "int32",
        "rating": "float32",
    }

    # Äá»c theo chunks
    chunksize = 1_000_000  # 1 triá»‡u dÃ²ng/chunk (Ä‘iá»u chá»‰nh náº¿u cáº§n)
    reader = pd.read_csv(
        file_path,
        chunksize=chunksize,
        low_memory=True,
        engine="c",
        iterator=True,
    )

    chunks: List[pd.DataFrame] = []
    total = 0
    for chunk in reader:
        # Chuáº©n hoÃ¡ tÃªn cá»™t vÃ  map biáº¿n thá»ƒ
        chunk = _normalize_columns(chunk)

        # Náº¿u thiáº¿u cá»™t báº¯t buá»™c -> bÃ¡o lá»—i sá»›m
        required = {"userId", "movieId", "rating"}
        if not required.issubset(chunk.columns):
            raise ValueError(f"âŒ Thiáº¿u cá»™t {sorted(required)} trong file. Columns: {chunk.columns.tolist()}")

        # Ã‰p kiá»ƒu nháº¹ cho cÃ¡c cá»™t cÃ³ thá»ƒ cÃ³
        for col, dt in dtype_hint.items():
            if col in chunk.columns:
                chunk[col] = chunk[col].astype(dt, copy=False)

        # Parse "date" náº¿u cÃ³; Ä‘á»ƒ tiáº¿t kiá»‡m, chá»‰ parse khi cá»™t tá»“n táº¡i
        if "date" in chunk.columns and not pd.api.types.is_datetime64_any_dtype(chunk["date"]):
            # errors='coerce' Ä‘á»ƒ khÃ´ng vá»¡ náº¿u cÃ³ vÃ i giÃ¡ trá»‹ láº¡
            chunk["date"] = pd.to_datetime(chunk["date"], errors="coerce")

        chunks.append(chunk)
        total += len(chunk)
        if nrows is not None and total >= nrows:
            # cáº¯t bá»›t pháº§n dÆ° cá»§a chunk cuá»‘i Ä‘á»ƒ Ä‘Ãºng nrows
            over = total - nrows
            if over > 0:
                chunks[-1] = chunks[-1].iloc[:-over]
            break

    if not chunks:
        raise ValueError("âŒ File rá»—ng hoáº·c khÃ´ng Ä‘á»c Ä‘Æ°á»£c dá»¯ liá»‡u.")

    ratings = pd.concat(chunks, ignore_index=True)

    # Náº¿u toÃ n bá»™ cá»™t 'date' Ä‘á»u NaT (hoáº·c khÃ´ng cÃ³), loáº¡i bá» Ä‘á»ƒ downstream tá»± xá»­ lÃ½ thá»© tá»±
    if "date" in ratings.columns and ratings["date"].isna().all():
        ratings.drop(columns=["date"], inplace=True)

    # Movies duy nháº¥t
    movies = pd.DataFrame({"movieId": pd.Series(ratings["movieId"].unique(), dtype="int32")})

    # Thá»‘ng kÃª nhanh
    n = len(ratings)
    n_users = ratings["userId"].nunique()
    n_items = ratings["movieId"].nunique()
    print(f"âœ… Äá»c {n:,} dÃ²ng | users: {n_users:,} | movies: {n_items:,}")
    if "date" in ratings.columns:
        try:
            dmin, dmax = ratings["date"].min(), ratings["date"].max()
            if pd.notna(dmin) and pd.notna(dmax):
                print(f"   â†’ Khoáº£ng thá»i gian: {dmin.date()} â†’ {dmax.date()}")
        except Exception:
            pass

    return ratings, movies, None
