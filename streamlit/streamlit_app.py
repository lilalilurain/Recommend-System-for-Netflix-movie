# app.py
import argparse
import os
from io import BytesIO, StringIO
from pathlib import Path
import re

import pandas as pd
import streamlit as st

from main import run_pipeline

# =========================
# Page & constants
# =========================
st.set_page_config(page_title="H·ªá th·ªëng g·ª£i √Ω phim cho Netflix", page_icon="üé¨", layout="wide")
st.title("üé¨ H·ªá th·ªëng ƒë·ªÅ xu·∫•t phim Netflix")
st.caption("H·ªá th·ªëng g·ª£i √Ω phim Netflix c√≥ kh·∫£ nƒÉng ph√°t hi·ªán v√† gi·∫£m thi·ªÉu ƒë√°nh gi√° gi·∫£ (shilling attacks).")

UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)

# =========================
# Helpers
# =========================
def save_uploaded_file(uploaded_file, dest_path: Path) -> Path:
    with open(dest_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return dest_path


@st.cache_data(show_spinner=False)
def preview_txt_from_bytes(file_bytes: bytes, n_preview: int = 50) -> pd.DataFrame | None:
    if not file_bytes:
        return None

    preview_data = file_bytes[:1 * 1024 * 1024]  # 1MB
    encodings_to_try = ['utf-8', 'latin1', 'cp1252', 'ISO-8859-1']

    for encoding in encodings_to_try:
        try:
            txt_io = StringIO(preview_data.decode(encoding, errors="ignore"))
            separators = [",", "\t", ";", "::", "|", r'\s+']
            for sep in separators:
                try:
                    df = pd.read_csv(txt_io, sep=sep, nrows=n_preview, engine='python',
                                     header=None, names=["userID", "movieID", "rating", "date"])
                    if df.shape[1] == 4:
                        return df
                except Exception:
                    txt_io.seek(0)
                    continue
        except UnicodeDecodeError:
            continue
    return None


@st.cache_data(show_spinner=False)
def load_titles_csv_from_bytes(file_bytes: bytes) -> pd.DataFrame | None:
    if not file_bytes:
        return None

    bio = BytesIO(file_bytes)
    encodings_to_try = ['utf-8', 'latin1', 'cp1252', 'ISO-8859-1']

    for encoding in encodings_to_try:
        try:
            bio.seek(0)
            df = pd.read_csv(
                bio,
                header=None,
                names=["movieId", "year", "title"],
                usecols=[0, 1, 2],
                encoding=encoding
            )

            if df.shape[1] == 3:
                df["movieId"] = pd.to_numeric(df["movieId"], errors="coerce")
                df = df.dropna(subset=["movieId"]).astype({"movieId": "int64"})

                if "year" in df.columns:
                    df["year"] = pd.to_numeric(df["year"], errors="coerce")
                if "title" in df.columns:
                    df["title"] = df["title"].astype(str).str.strip()

                return df
        except Exception:
            continue

    st.warning("Kh√¥ng th·ªÉ ƒë·ªçc file CSV. Vui l√≤ng ki·ªÉm tra l·∫°i m√£ h√≥a v√† c·∫•u tr√∫c.")
    return None

# =========================
# Sidebar ‚Äì upload d·ªØ li·ªáu
# =========================
st.sidebar.header("‚öôÔ∏è C·∫•u h√¨nh d·ªØ li·ªáu")

dataset_file = st.sidebar.file_uploader(
    "T·∫£i l√™n **merged.txt** (userID,movieID,rating,date) ‚Äî ƒë√£ n√¢ng gi·ªõi h·∫°n upload trong config",
    type=["txt", "csv"],
)

titles_file = st.sidebar.file_uploader(
    "T·∫£i l√™n **movie_tittles.csv** (movieId,year,title ‚Äì KH√îNG header)",
    type=["csv"],
)

titles_df = load_titles_csv_from_bytes(titles_file.getvalue()) if titles_file else None
if titles_df is not None:
    st.sidebar.success(f"ƒê√£ ƒë·ªçc {len(titles_df):,} ti√™u ƒë·ªÅ")
else:
    st.sidebar.info("Ch∆∞a t·∫£i titles.")

# =========================
# Main preview & tra c·ª©u
# =========================
st.info("Upload **merged.txt** v√† **movie_tittles.csv** ·ªü thanh b√™n, sau ƒë√≥ nh·∫•n **Ch·∫°y th·ª≠ nghi·ªám** ƒë·ªÉ ch·∫°y.")

colA, colB = st.columns(2)
with colA:
    st.subheader("üëÄ Xem tr∆∞·ªõc merged.txt")
    if dataset_file is not None:
        prev = preview_txt_from_bytes(dataset_file.getvalue())
        if prev is not None:
            st.dataframe(prev.head(20), use_container_width=True)
        else:
            st.caption("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c preview (file qu√° l·ªõn ho·∫∑c ƒë·ªãnh d·∫°ng kh√¥ng h·ª£p l·ªá?).")
    else:
        st.caption("Ch∆∞a upload merged.txt.")

with colB:
    st.subheader("üìã Xem tr∆∞·ªõc ti√™u ƒë·ªÅ (movie_tittles.csv)")
    if titles_df is not None and not titles_df.empty:
        st.dataframe(titles_df.head(20), use_container_width=True)
    else:
        st.caption("Ch∆∞a upload ho·∫∑c file r·ªóng.")

# =========================
# Tra c·ª©u phim
# =========================
st.subheader("üîç Tra c·ª©u phim")
if titles_df is not None and not titles_df.empty:
    tab1, tab2 = st.tabs(["Theo movieId", "Theo t√™n phim"])

    with tab1:
        q_id = st.number_input("Nh·∫≠p movieId", min_value=1, value=1)
        found = titles_df.loc[titles_df["movieId"] == int(q_id)]
        if not found.empty:
            row = found.iloc[0]
            yr = "" if pd.isna(row.get("year")) else int(row.get("year"))
            st.success(f"üé• {row['title']}{f' ({yr})' if yr else ''}")
        else:
            st.info("Kh√¥ng t√¨m th·∫•y movieId n√†y trong danh s√°ch.")

    with tab2:
        q_title = st.text_input("Nh·∫≠p t√™n phim", value="")
        if q_title.strip():
            matches = titles_df[titles_df["title"].str.lower().str.contains(q_title.strip().lower())]
            if not matches.empty:
                st.write(f"üîé T√¨m th·∫•y {len(matches)} k·∫øt qu·∫£:")
                st.dataframe(matches[["movieId", "title", "year"]], use_container_width=True)
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y phim n√†o kh·ªõp v·ªõi t√™n ƒë√£ nh·∫≠p.")
else:
    st.caption("C·∫ßn upload movie_tittles.csv ƒë·ªÉ tra c·ª©u.")

st.markdown("---")
with st.form("params_form"):
    st.subheader("‚öôÔ∏è Tham s·ªë ch·∫°y th·ª≠ nghi·ªám")

    col1, col2 = st.columns(2)
    with col1:
        recommender = st.selectbox("Thu·∫≠t to√°n g·ª£i √Ω", ["cf", "hybrid"])
        detector = st.selectbox("B·ªô ph√°t hi·ªán", ["random_forest", "isolation_forest"])
        suspicious_action = st.selectbox("X·ª≠ l√Ω user ƒë√°ng ng·ªù", ["filter", "downweight"])
        simulate_attacks = st.checkbox("Gi·∫£ l·∫≠p t·∫•n c√¥ng", value=True)

    with col2:
        epochs = st.number_input("Epochs", min_value=1, max_value=100, value=10)
        factors = st.number_input("S·ªë latent factors", min_value=1, max_value=200, value=20)
        downweight = st.slider("Tr·ªçng s·ªë downweight", 0.1, 1.0, 0.5)
        alpha = st.slider("Alpha (trong Hybrid)", 0.0, 1.0, 0.5)

    submitted = st.form_submit_button("üöÄ Ch·∫°y th·ª≠ nghi·ªám")

if submitted and dataset_file is not None:
    with st.spinner("ƒêang ch·∫°y pipeline..."):
        data_path = save_uploaded_file(dataset_file, UPLOAD_DIR / "merged.txt")

        args = argparse.Namespace(
            data_dir=UPLOAD_DIR,
            nrows=None,
            test_ratio=0.2,
            simulate_attacks=simulate_attacks,
            attack_type="random",
            n_attack_users=200,
            filler_ratio=0.1,
            target_movie_id=1,
            min_rating=1.0,
            max_rating=5.0,
            detector=detector,
            contamination=0.05,
            suspicious_action=suspicious_action,
            downweight=downweight,
            factors=factors,
            lr=0.01,
            reg=0.02,
            epochs=epochs,
            alpha=alpha,
            recommender=recommender,
            topk=10,
            like_threshold=4.0,
            seed=42,
        )

        results, figs = run_pipeline(args, return_results=True)
        st.success("‚úÖ ƒê√£ ch·∫°y xong!")

        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        st.json(results)

        if figs:
            for name, path in figs.items():
                st.image(path, caption=name)


# =========================
# Run pipeline
# =========================
st.warning("C·∫ßn b·ªï sung form nh·∫≠p tham s·ªë cho pipeline tr∆∞·ªõc khi ch·∫°y.")
